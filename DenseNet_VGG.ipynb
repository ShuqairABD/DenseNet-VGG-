{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eHMmaySbyT0s",
        "jkpLBuZ7yQoG",
        "erJobTW3yCB_",
        "UGNt2LXLOHn3",
        "wZcm1SoUy29N"
      ],
      "gpuType": "T4",
      "mount_file_id": "1Lmz8Q_-9J4WHWV9gJnGNjMRYqSNWhTZ9",
      "authorship_tag": "ABX9TyNEmnhK3tD/yAGbm06lY6ox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShuqairABD/DenseNet-VGG-/blob/main/DenseNet_VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **start**"
      ],
      "metadata": {
        "id": "eHMmaySbyT0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "GNvqRR7owh5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import albumentations as A\n",
        "from torchvision.transforms import v2\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import PIL\n",
        "from pathlib import Path\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "from torchsummary import summary\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import random\n",
        "import pandas as pd\n",
        "import pprint\n",
        "from tabulate import tabulate\n",
        "\n",
        "import torchvision.models as models\n",
        "from torch.optim import Adam\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "from torchvision import models, transforms, datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "-D0bOACEwkdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import time\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "2iiniwQ7vjEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VGG**"
      ],
      "metadata": {
        "id": "jkpLBuZ7yQoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь к папке\n",
        "data_dir = '/content/drive/MyDrive/WEATHER'\n",
        "\n",
        "# преобразования для данных\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Загрузка данные\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)\n",
        "\n",
        "# Разделить данные на обучающую и валидационную выборки\n",
        "train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42, stratify=dataset.targets)\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Загрузка предобученную модель VGG16\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Изменяем последний слой для классификации на два класса\n",
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Перемещаем модель на GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# критерий потерь и оптимизатор\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfm2Pk0U1XrM",
        "outputId": "8ce1be94-0d8c-44fc-dd42-82ec4628ffd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:10<00:00, 52.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для обучения модели\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=25, save_path='model.pth'):\n",
        "    start_time = time.time()\n",
        "    print(\"Training started\")\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Training Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        corrects = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                corrects += torch.sum(preds == labels.data)\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = corrects.double() / len(val_loader.dataset)\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
        "\n",
        "        # сохранение наилучшей модели\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Training completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s')\n",
        "    print(f'Best validation accuracy: {best_acc:.4f}')\n",
        "\n",
        "    # Загрузка лучших весов модели\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    # Сохранение модели\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f'Model saved to {save_path}')\n",
        "\n",
        "# Обучаем модель\n",
        "train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10, save_path='VGG_model.pth')\n"
      ],
      "metadata": {
        "id": "5iK0Qbso1I3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfceaf9c-8dfa-44f0-f179-ff9640751448",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started\n",
            "Epoch 1/10\n",
            "Training Loss: 0.0806\n",
            "Validation Loss: 0.0650, Accuracy: 0.9763\n",
            "Epoch 2/10\n",
            "Training Loss: 0.0262\n",
            "Validation Loss: 0.0419, Accuracy: 0.9858\n",
            "Epoch 3/10\n",
            "Training Loss: 0.0171\n",
            "Validation Loss: 0.0332, Accuracy: 0.9873\n",
            "Epoch 4/10\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0419, Accuracy: 0.9873\n",
            "Epoch 5/10\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0327, Accuracy: 0.9896\n",
            "Epoch 6/10\n",
            "Training Loss: 0.0057\n",
            "Validation Loss: 0.0463, Accuracy: 0.9887\n",
            "Epoch 7/10\n",
            "Training Loss: 0.0037\n",
            "Validation Loss: 0.0372, Accuracy: 0.9893\n",
            "Epoch 8/10\n",
            "Training Loss: 0.0031\n",
            "Validation Loss: 0.0427, Accuracy: 0.9899\n",
            "Epoch 9/10\n",
            "Training Loss: 0.0044\n",
            "Validation Loss: 0.0487, Accuracy: 0.9873\n",
            "Epoch 10/10\n",
            "Training Loss: 0.0031\n",
            "Validation Loss: 0.0379, Accuracy: 0.9887\n",
            "Training completed in 64m 59s\n",
            "Best validation accuracy: 0.9899\n",
            "Model saved to VGG_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **test VGG**"
      ],
      "metadata": {
        "id": "erJobTW3yCB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Путь к папке (test)\n",
        "test_data_dir = '/content/drive/MyDrive/test_images'\n",
        "\n",
        "#преобразования для данных\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# предобученной модели VGG16\n",
        "model = models.vgg16(pretrained=True)\n",
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] = torch.nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Перемещаем модель на GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Загрузка обученной модели\n",
        "model.load_state_dict(torch.load('/content/VGG_model.pth'))\n",
        "\n",
        "# отображения изображения\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Denormalize and show an image\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "# Функция для тестирования модели\n",
        "def test_model(model, data_dir, class_names):\n",
        "    model.eval()\n",
        "    images = []\n",
        "    image_paths = [os.path.join(data_dir, img) for img in os.listdir(data_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = data_transforms(image)\n",
        "        images.append((image, image_path))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, image_path in images:\n",
        "            input_tensor = image.unsqueeze(0).to(device)\n",
        "            outputs = model(input_tensor)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Визуализация изображения и предсказания\n",
        "            plt.figure()\n",
        "            imshow(image.cpu(), title=f'Predicted: {class_names[preds[0]]}')\n",
        "            plt.show()\n",
        "\n",
        "# имена классов\n",
        "class_names = ['cold_season', 'warm_season']\n",
        "\n",
        "# Тест модель\n",
        "test_model(model, test_data_dir, class_names)\n"
      ],
      "metadata": {
        "id": "xBab15blyE11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VGG sigmoid**"
      ],
      "metadata": {
        "id": "UGNt2LXLOHn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Путь к папке с изображениями\n",
        "data_dir = '/content/drive/MyDrive/WEATHER'\n",
        "\n",
        "# преобразования данных\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Загружаем данные\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)\n",
        "\n",
        "# Разделяем данные\n",
        "train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42, stratify=dataset.targets)\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "#  модель VGG16\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Изменяем последний слой для бинарной классификации\n",
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Перемещаем модель на GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# потерь и оптимизатор\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Функция для обучения модели\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=25):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.float().unsqueeze(1).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        corrects = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.float().unsqueeze(1).to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                preds = (outputs > 0.5).float()\n",
        "                corrects += torch.sum(preds == labels.data)\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = corrects.double() / len(val_loader.dataset)\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
        "\n",
        "        # Сохранение модели\n",
        "        torch.save(model.state_dict(), f'vgg_model_epoch_{epoch+1}.pth')\n",
        "\n",
        "# Обучаем модель\n",
        "train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=5)\n"
      ],
      "metadata": {
        "id": "jRb0eXa_OLpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**test VGG sigmoid**"
      ],
      "metadata": {
        "id": "cvMio3gHOUOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Путь к папке с тестовыми изображениями\n",
        "test_data_dir = '/content/drive/MyDrive/test_images'\n",
        "\n",
        "# Определяем преобразования для данных\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Загрузка предобученной модели VGG16 и изменение последнего слоя\n",
        "model = models.vgg16(pretrained=True)\n",
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] = torch.nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Перемещаем модель на GPU, если доступно\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Загрузка обученной модели\n",
        "model.load_state_dict(torch.load('vgg_model_epoch_5.pth'))\n",
        "\n",
        "# Функция для отображения изображения\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Denormalize and show an image\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "# Функция для тестирования модели\n",
        "def test_model(model, data_dir, class_names):\n",
        "    model.eval()\n",
        "    images = []\n",
        "    image_paths = [os.path.join(data_dir, img) for img in os.listdir(data_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = data_transforms(image)\n",
        "        images.append((image, image_path))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, image_path in images:\n",
        "            input_tensor = image.unsqueeze(0).to(device)\n",
        "            outputs = model(input_tensor)\n",
        "            preds = (outputs > 0.5).float()\n",
        "\n",
        "            # Визуализация изображения и предсказания\n",
        "            plt.figure()\n",
        "            imshow(image.cpu(), title=f'Predicted: {class_names[int(preds[0].item())]}')\n",
        "            plt.show()\n",
        "\n",
        "# Определяем имена классов\n",
        "class_names = ['cold_season', 'warm_season']\n",
        "\n",
        "# Тестируем модель и визуализируем предсказания\n",
        "test_model(model, test_data_dir, class_names)\n"
      ],
      "metadata": {
        "id": "jlEhxsMPOXnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**save weights to drive**"
      ],
      "metadata": {
        "id": "x60CTzSoIhzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Копирование файла весов в Google Drive\n",
        "!cp /content/VGG_model.pth /content/drive/MyDrive/VGG_model.pth\n",
        "\n",
        "# Проверка наличия файла в Google Drive\n",
        "!ls /content/drive/MyDrive/\n",
        "\n",
        "# Проверка размера файла в Google Drive\n",
        "!ls -lh /content/VGG_model.pth\n",
        "\n",
        "# Проверка размера исходного файла в Colab\n",
        "!ls -lh /content/VGG_model.pth"
      ],
      "metadata": {
        "id": "47DtC2FO2VC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DenseNet**"
      ],
      "metadata": {
        "id": "wZcm1SoUy29N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Путь к папке\n",
        "data_dir = '/content/drive/MyDrive/WEATHER'\n",
        "\n",
        "# преобразования для данных\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Загрузка данные\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)\n",
        "\n",
        "# Разделить данные на обучающую и валидационную выборки\n",
        "train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42, stratify=dataset.targets)\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# предобученную модель DenseNet121\n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "# Изменяем последний слой для классификации на два класса\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Перемещаем модель на GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# критерия потерь и оптимизатор\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
        "\n",
        "# Функция для обучения модели\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=3, save_path='model.pth'):\n",
        "    start_time = time.time()\n",
        "    print(\"Training started\")\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Training Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        corrects = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                corrects += torch.sum(preds == labels.data)\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = corrects.double() / len(val_loader.dataset)\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
        "\n",
        "        # Сохранение наилучшей модели\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Training completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s')\n",
        "    print(f'Best validation accuracy: {best_acc:.4f}')\n",
        "\n",
        "    # Загрузка лучших весов модели\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    # Сохранение модели\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f'Model saved to {save_path}')\n",
        "\n",
        "# Обучаем модель\n",
        "num_epochs = 25\n",
        "train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=num_epochs, save_path='densenet_model_2.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tD9U-R0hSCwb",
        "outputId": "d591e51b-0258-4a86-b4e3-8f1b03a0d12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started\n",
            "Epoch 1/25\n",
            "Training Loss: 0.0961\n",
            "Validation Loss: 0.0356, Accuracy: 0.9861\n",
            "Epoch 2/25\n",
            "Training Loss: 0.0377\n",
            "Validation Loss: 0.0387, Accuracy: 0.9858\n",
            "Epoch 3/25\n",
            "Training Loss: 0.0168\n",
            "Validation Loss: 0.0303, Accuracy: 0.9884\n",
            "Epoch 4/25\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0298, Accuracy: 0.9905\n",
            "Epoch 5/25\n",
            "Training Loss: 0.0072\n",
            "Validation Loss: 0.0363, Accuracy: 0.9882\n",
            "Epoch 6/25\n",
            "Training Loss: 0.0058\n",
            "Validation Loss: 0.0305, Accuracy: 0.9902\n",
            "Epoch 7/25\n",
            "Training Loss: 0.0049\n",
            "Validation Loss: 0.0355, Accuracy: 0.9873\n",
            "Epoch 8/25\n",
            "Training Loss: 0.0049\n",
            "Validation Loss: 0.0365, Accuracy: 0.9899\n",
            "Epoch 9/25\n",
            "Training Loss: 0.0042\n",
            "Validation Loss: 0.0325, Accuracy: 0.9896\n",
            "Epoch 10/25\n",
            "Training Loss: 0.0030\n",
            "Validation Loss: 0.0318, Accuracy: 0.9905\n",
            "Epoch 11/25\n",
            "Training Loss: 0.0030\n",
            "Validation Loss: 0.0319, Accuracy: 0.9902\n",
            "Epoch 12/25\n",
            "Training Loss: 0.0028\n",
            "Validation Loss: 0.0361, Accuracy: 0.9905\n",
            "Epoch 13/25\n",
            "Training Loss: 0.0026\n",
            "Validation Loss: 0.0337, Accuracy: 0.9902\n",
            "Epoch 14/25\n",
            "Training Loss: 0.0026\n",
            "Validation Loss: 0.0332, Accuracy: 0.9908\n",
            "Epoch 15/25\n",
            "Training Loss: 0.0030\n",
            "Validation Loss: 0.0411, Accuracy: 0.9879\n",
            "Epoch 16/25\n",
            "Training Loss: 0.0025\n",
            "Validation Loss: 0.0351, Accuracy: 0.9890\n",
            "Epoch 17/25\n",
            "Training Loss: 0.0029\n",
            "Validation Loss: 0.0386, Accuracy: 0.9890\n",
            "Epoch 18/25\n",
            "Training Loss: 0.0025\n",
            "Validation Loss: 0.0308, Accuracy: 0.9910\n",
            "Epoch 19/25\n",
            "Training Loss: 0.0023\n",
            "Validation Loss: 0.0319, Accuracy: 0.9899\n",
            "Epoch 20/25\n",
            "Training Loss: 0.0023\n",
            "Validation Loss: 0.0355, Accuracy: 0.9902\n",
            "Epoch 21/25\n",
            "Training Loss: 0.0022\n",
            "Validation Loss: 0.0326, Accuracy: 0.9890\n",
            "Epoch 22/25\n",
            "Training Loss: 0.0021\n",
            "Validation Loss: 0.0357, Accuracy: 0.9899\n",
            "Epoch 23/25\n",
            "Training Loss: 0.0024\n",
            "Validation Loss: 0.0419, Accuracy: 0.9882\n",
            "Epoch 24/25\n",
            "Training Loss: 0.0023\n",
            "Validation Loss: 0.0322, Accuracy: 0.9910\n",
            "Epoch 25/25\n",
            "Training Loss: 0.0020\n",
            "Validation Loss: 0.0323, Accuracy: 0.9910\n",
            "Training completed in 130m 9s\n",
            "Best validation accuracy: 0.9910\n",
            "Model saved to densenet_model_2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Копирование файла весов в Google Drive\n",
        "!cp /content/densenet_model_epoch_5.pth /content/drive/MyDrive/densenet_model_epoch_5.pth\n",
        "\n",
        "# Проверка наличия файла в Google Drive\n",
        "!ls /content/drive/MyDrive/\n",
        "\n",
        "# Проверка размера файла в Google Drive\n",
        "!ls -lh /content/densenet_model_epoch_5.pth\n",
        "\n",
        "# Проверка размера исходного файла в Colab\n",
        "!ls -lh /content/densenet_model_epoch_5.pth"
      ],
      "metadata": {
        "id": "tJTu_I91LBV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **test DenseNet**"
      ],
      "metadata": {
        "id": "QHOJxWJ68wRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Путь к папке\n",
        "test_data_dir = '/content/drive/MyDrive/test_images'\n",
        "\n",
        "# преобразования данных\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Загрузка предобученную модель DenseNet121\n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "# Изменяем последний слой для классификации на два класса\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Перемещаем модель на GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Загрузка обучанной модели\n",
        "model.load_state_dict(torch.load('/content/densenet_model_2.pth'))\n",
        "\n",
        "# Функция для отображения изображения\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Denormalize and show an image\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "# Функция для тестирования модели\n",
        "def test_model(model, data_dir, class_names):\n",
        "    model.eval()\n",
        "    images = []\n",
        "    image_paths = [os.path.join(data_dir, img) for img in os.listdir(data_dir) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = data_transforms(image)\n",
        "        images.append((image, image_path))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, image_path in images:\n",
        "            input_tensor = image.unsqueeze(0).to(device)\n",
        "            outputs = model(input_tensor)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # изображения и предсказания\n",
        "            plt.figure()\n",
        "            imshow(image.cpu(), title=f'Predicted: {class_names[preds[0]]}')\n",
        "            plt.show()\n",
        "\n",
        "# имена классов\n",
        "class_names = ['cold_season', 'warm_season']\n",
        "\n",
        "# Тест модель\n",
        "test_model(model, test_data_dir, class_names)\n"
      ],
      "metadata": {
        "id": "UBv9G1_l8y9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DenseNet sigmoid**"
      ],
      "metadata": {
        "id": "RJR2IqdxPBfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Путь\n",
        "data_dir = '/content/drive/MyDrive/WEATHER'\n",
        "\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Загружаем данные\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)\n",
        "\n",
        "# обучающую и валидационную выборки\n",
        "train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42, stratify=dataset.targets)\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# предобученную модель DenseNet121\n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "# последний слой для бинарной классификации\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Перемещаем модель на GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# критерий потерь и оптимизатор\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Функция для обучения модели\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=25):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.float().unsqueeze(1).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        corrects = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.float().unsqueeze(1).to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                preds = (outputs > 0.5).float()\n",
        "                corrects += torch.sum(preds == labels.data)\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = corrects.double() / len(val_loader.dataset)\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
        "\n",
        "        # Сохранение модель\n",
        "        torch.save(model.state_dict(), f'densenet_model_epoch_{epoch+1}.pth')\n",
        "\n",
        "# Обучаем модель\n",
        "train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=5)\n"
      ],
      "metadata": {
        "id": "N_qiFkaWPF3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e92374c-efab-4fed-9598-89693065043e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.1301\n",
            "Validation Loss: 0.0485, Accuracy: 0.9827\n",
            "Epoch 2/5, Loss: 0.0434\n",
            "Validation Loss: 0.0370, Accuracy: 0.9876\n",
            "Epoch 3/5, Loss: 0.0253\n",
            "Validation Loss: 0.0343, Accuracy: 0.9884\n",
            "Epoch 4/5, Loss: 0.0142\n",
            "Validation Loss: 0.0342, Accuracy: 0.9884\n",
            "Epoch 5/5, Loss: 0.0133\n",
            "Validation Loss: 0.0320, Accuracy: 0.9908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **test DenseNet sigmoid**"
      ],
      "metadata": {
        "id": "T6HwaN5BPGzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Путь к папке\n",
        "test_data_dir = '/content/drive/MyDrive/test_images'\n",
        "\n",
        "# преобразования для данных\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# DenseNet121\n",
        "model = models.densenet121(pretrained=True)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Перемещаем модель на GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# обученной модель\n",
        "model.load_state_dict(torch.load('/content/densenet_model_epoch_5.pth'))\n",
        "\n",
        "# Функция для отображения изображения\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Denormalize and show an image\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "# Функция для тестирования модели\n",
        "def test_model(model, data_dir, class_names):\n",
        "    model.eval()\n",
        "    images = []\n",
        "    image_paths = [os.path.join(data_dir, img) for img in os.listdir(data_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = data_transforms(image)\n",
        "        images.append((image, image_path))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, image_path in images:\n",
        "            input_tensor = image.unsqueeze(0).to(device)\n",
        "            outputs = model(input_tensor)\n",
        "            preds = (outputs > 0.5).float()\n",
        "\n",
        "            # изображения и предсказания\n",
        "            plt.figure()\n",
        "            imshow(image.cpu(), title=f'Predicted: {class_names[int(preds[0].item())]}')\n",
        "            plt.show()\n",
        "\n",
        "# имена классов\n",
        "class_names = ['cold_season', 'warm_season']\n",
        "\n",
        "# Тест модель\n",
        "test_model(model, test_data_dir, class_names)\n"
      ],
      "metadata": {
        "id": "R6XYZ2wIPLqX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}